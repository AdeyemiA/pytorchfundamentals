{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Concepts, Transforms and Visualizations\n",
    "\n",
    "Now that we have our dataset downloaded and yes/no labels parsed out. Lets think learn a little more about audio data and concepts by visualization and transform this dataset.\n",
    "\n",
    "## Sample Rate\n",
    "\n",
    "First lets think about the digital representation of analog sound. How does sound get recorded anyway?! Just like with images we need to take our physical world and convert it to numbers or a digital represnation for a computer to understand. For audio, a microphone is used to capture the sound and then its converted from analog sound to digital sound by sampling at consitent intervals of time. This is called the `sample rate`. The higher the `sample rate` the higher the quality of the sound. The average sound sample rate is 48 kHz or 48,000 samples per second. This dataset was sampled at 16kHz so our sample rate is 16,000.\n",
    "\n",
    "With any machine learning dataset we want to make it as small as possible while not loosing the accuracy of our model. We are going to keep this sample rate however if you could play around with reducing the sampel rate of the audio to make the model smaller and see if it effects the quality of the model.\n",
    "\n",
    "Lets take a look at the dataset, visualize and transform it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_waveform = trainset_speechcommands_yes[0][0]\n",
    "yes_sample_rate = trainset_speechcommands_yes[0][1]\n",
    "print(f'Waveform: {yes_waveform}')\n",
    "print(f'Sample Rate: {yes_sample_rate}')\n",
    "print(f'Label: {trainset_speechcommands_yes[0][2]}')\n",
    "print(f'ID: {trainset_speechcommands_yes[0][3]}')\n",
    "#print(f'Something: {trainset_speechcommands_yes[0][4]}')\n",
    "\n",
    "no_waveform = trainset_speechcommands_no[0][0]\n",
    "no_sample_rate = trainset_speechcommands_no[0][1]\n",
    "print(f'Waveform: {no_waveform}')\n",
    "print(f'Sample Rate: {no_sample_rate}')\n",
    "print(f'Label: {trainset_speechcommands_no[0][2]}')\n",
    "print(f'ID: {trainset_speechcommands_no[0][3]}')\n",
    "#print(f'Something: {trainset_speechcommands_no[0][4]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waveform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_waveform(waveform, sample_rate, label):\n",
    "    print(\"Waveform: {}\\nSample rate: {}\\nLabels: {}\".format(waveform, sample_rate, label))\n",
    "    new_sample_rate = sample_rate/10\n",
    "    print(new_sample_rate)\n",
    "    # Since Resample applies to a single channel, we resample first channel here\n",
    "    channel = 0\n",
    "    waveform_transformed = torchaudio.transforms.Resample(sample_rate, new_sample_rate)(waveform[channel,:].view(1,-1))\n",
    "\n",
    "    print(\"Shape of transformed waveform: {}\".format(waveform_transformed.size()))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(waveform_transformed[0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_waveform(yes_waveform, yes_sample_rate, 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_spectrogram(waveform):\n",
    "    spectrogram = torchaudio.transforms.Spectrogram()(waveform)\n",
    "    #print(spectrogram)\n",
    "    print(\"Shape of spectrogram: {}\".format(spectrogram.size()))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(spectrogram.log2()[0,:,:].numpy(), cmap='gray')\n",
    "    #plt.imsave(f'test/spectrogram_img.png', spectrogram.log2()[0,:,:].numpy(), cmap='gray')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_spectrogram(yes_waveform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mel Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_melspectrogram(waveform,sample_rate):\n",
    "    mel_spectrogram = torchaudio.transforms.MelSpectrogram()(waveform)\n",
    "    print(\"Shape of spectrogram: {}\".format(mel_spectrogram.size()))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(mel_spectrogram.log2()[0,:,:].numpy(), cmap='gray')\n",
    "    #plt.imsave(f'test/mfcc_img.png', mfcc_spectrogram.log2()[0,:,:].numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_melspectrogram(yes_waveform, yes_sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mfcc(waveform,sample_rate):\n",
    "    mfcc_spectrogram = torchaudio.transforms.MFCC(sample_rate= sample_rate)(waveform)\n",
    "    print(\"Shape of spectrogram: {}\".format(mfcc_spectrogram.size()))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(mfcc_spectrogram.log2()[0,:,:].numpy(), cmap='gray')\n",
    "    #plt.imsave(f'test/mfcc_img.png', mfcc_spectrogram.log2()[0,:,:].numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_mfcc(yes_waveform, yes_sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
